# Story: Worker Pool Management

**Story ID**: STORY-041  
**Epic**: EPIC-003-function-runner-architecture  
**Type**: Infrastructure  
**Points**: 8 (Large)  
**Priority**: High  
**Status**: âœ… Completed  

## Story Description
As a system administrator, I want a robust worker pool management system that can dynamically scale function runners based on load, manage worker lifecycle, and ensure efficient resource utilization, so that the system can handle varying workloads while maintaining performance and stability.

## Acceptance Criteria

### Functional Requirements
- [ ] Worker pool can dynamically scale between minimum and maximum worker counts
- [ ] Workers are automatically spawned when task queue grows beyond threshold
- [ ] Workers are gracefully terminated when idle for configurable duration
- [ ] System monitors worker health and restarts failed workers automatically
- [ ] Worker pool respects resource limits (CPU, memory, GPU allocation)
- [ ] Administrative interface shows real-time worker status and metrics
- [ ] Workers can be manually scaled up/down through API or UI
- [ ] System prevents resource exhaustion through intelligent queuing

### Technical Requirements
- [ ] Implement `WorkerPoolManager` class with lifecycle management
- [ ] Create worker health monitoring with heartbeat mechanism
- [ ] Implement graceful shutdown with task completion guarantees
- [ ] Configure Celery autoscaling with custom scaling strategy
- [ ] Create worker resource tracking (CPU, memory, GPU usage)
- [ ] Implement worker process isolation for security and stability
- [ ] Add Redis-based worker registry for distributed tracking
- [ ] Create metrics collection for worker performance analysis

### Quality Requirements
- [ ] Worker spawn time < 5 seconds under normal load
- [ ] Zero task loss during worker scaling operations
- [ ] Worker health check frequency configurable (default 30s)
- [ ] Resource usage tracking accuracy > 95%
- [ ] Graceful shutdown timeout configurable (default 60s)
- [ ] Worker crash recovery time < 10 seconds
- [ ] Support for heterogeneous worker types (CPU/GPU)

## Implementation Notes

### Worker Pool Architecture
```python
class WorkerPoolManager:
    """Manages lifecycle of function runner workers"""
    
    def __init__(self, 
                 min_workers: int = 1,
                 max_workers: int = 10,
                 scale_up_threshold: int = 5,
                 scale_down_threshold: int = 0,
                 idle_timeout: int = 300):
        self.min_workers = min_workers
        self.max_workers = max_workers
        self.workers: Dict[str, WorkerInfo] = {}
        self.resource_monitor = ResourceMonitor()
        self.health_checker = HealthChecker()
    
    async def scale_workers(self):
        """Dynamic scaling based on queue depth and resources"""
        queue_depth = await self.get_queue_depth()
        active_workers = len(self.get_active_workers())
        
        if queue_depth > self.scale_up_threshold * active_workers:
            await self.spawn_worker()
        elif queue_depth < self.scale_down_threshold:
            await self.terminate_idle_worker()
    
    async def spawn_worker(self, worker_type: str = "general"):
        """Spawn new worker with resource allocation"""
        if not self.resource_monitor.can_spawn_worker(worker_type):
            logger.warning("Insufficient resources for new worker")
            return
        
        worker_id = f"worker_{uuid.uuid4().hex[:8]}"
        resources = self.resource_monitor.allocate(worker_type)
        
        worker = Worker(
            id=worker_id,
            type=worker_type,
            resources=resources,
            queues=self.get_queues_for_type(worker_type)
        )
        
        await worker.start()
        self.workers[worker_id] = WorkerInfo(
            worker=worker,
            started_at=datetime.now(),
            last_heartbeat=datetime.now()
        )
```

### Celery Configuration
```python
# celery_config.py
from celery import Celery
from kombu import Queue

app = Celery('auteur')

app.conf.update(
    broker_url='redis://redis:6379/0',
    result_backend='redis://redis:6379/0',
    
    # Worker pool settings
    worker_prefetch_multiplier=1,
    worker_max_tasks_per_child=100,
    worker_disable_rate_limits=True,
    
    # Autoscaling settings
    worker_autoscaler='auteur.workers.CustomAutoscaler',
    worker_autoscale_max=10,
    worker_autoscale_min=1,
    
    # Task routing
    task_routes={
        'auteur.tasks.generate.*': {'queue': 'gpu'},
        'auteur.tasks.process.*': {'queue': 'cpu'},
        'auteur.tasks.io.*': {'queue': 'io'}
    },
    
    # Queues configuration
    task_queues=[
        Queue('gpu', routing_key='gpu', priority=10),
        Queue('cpu', routing_key='cpu', priority=5),
        Queue('io', routing_key='io', priority=1),
    ]
)
```

### Health Monitoring
```python
class HealthChecker:
    """Monitor worker health and performance"""
    
    async def check_worker_health(self, worker_id: str) -> HealthStatus:
        """Comprehensive health check for worker"""
        checks = [
            self.check_heartbeat(worker_id),
            self.check_memory_usage(worker_id),
            self.check_task_completion_rate(worker_id),
            self.check_error_rate(worker_id)
        ]
        
        results = await asyncio.gather(*checks)
        return HealthStatus(
            healthy=all(r.passed for r in results),
            checks=results,
            timestamp=datetime.now()
        )
    
    async def monitor_all_workers(self):
        """Continuous monitoring loop"""
        while True:
            for worker_id in self.pool_manager.workers:
                status = await self.check_worker_health(worker_id)
                
                if not status.healthy:
                    await self.handle_unhealthy_worker(worker_id, status)
                
                await self.publish_metrics(worker_id, status)
            
            await asyncio.sleep(self.check_interval)
```

### Resource Management
```python
class ResourceMonitor:
    """Track and allocate system resources"""
    
    def __init__(self):
        self.total_resources = self.detect_system_resources()
        self.allocated = ResourceAllocation()
    
    def detect_system_resources(self) -> SystemResources:
        """Detect available CPU, memory, and GPU resources"""
        return SystemResources(
            cpu_cores=psutil.cpu_count(),
            memory_gb=psutil.virtual_memory().total / (1024**3),
            gpus=self.detect_gpus()
        )
    
    def can_spawn_worker(self, worker_type: str) -> bool:
        """Check if resources available for worker type"""
        required = self.get_requirements(worker_type)
        available = self.get_available_resources()
        
        return (
            available.cpu_cores >= required.cpu_cores and
            available.memory_gb >= required.memory_gb and
            (not required.gpu or available.gpu_count > 0)
        )
```

## Dependencies
- **STORY-013**: Function Runner Foundation (completed) - provides base runner implementation
- **STORY-042**: Task Queue Configuration - requires queue setup for worker routing
- **STORY-043**: Worker Health Monitoring - integrates with health check system
- Redis for worker coordination and metrics
- Celery for distributed task processing
- psutil for resource monitoring

## Testing Criteria
- [ ] Unit tests for WorkerPoolManager scaling logic
- [ ] Integration tests for worker spawn/terminate lifecycle
- [ ] Load tests verifying scaling under various queue depths
- [ ] Stress tests for resource limit enforcement
- [ ] Fault injection tests for worker crash recovery
- [ ] Performance tests for worker spawn latency
- [ ] End-to-end tests for task completion during scaling

## Definition of Done
- [ ] WorkerPoolManager implemented with all scaling features
- [ ] Celery configuration supports multiple worker types
- [ ] Health monitoring system tracks all workers
- [ ] Resource allocation prevents oversubscription
- [ ] Metrics exported to monitoring system
- [ ] Administrative API endpoints documented
- [ ] Load testing shows < 5s spawn time
- [ ] Zero task loss verified under scaling operations
- [ ] Documentation includes scaling strategy guide
- [ ] Code review passed with test coverage > 90%

## Story Links
- **Depends On**: STORY-013 (Function Runner Foundation)
- **Blocks**: STORY-047 (API Client Layer)
- **Related Epic**: EPIC-003-function-runner-architecture
- **Architecture Ref**: /concept/foundation/architecture_summary.md